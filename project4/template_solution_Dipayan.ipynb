{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57002395eb6b50f8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Project 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a46aca0e5d9ef",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1c6ff7632991155",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from transformers import GPT2Config, GPT2Tokenizer, GPT2Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d9b5e89d4b3a02",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"mps\")\n",
    "BATCH_SIZE = 20  # TODO: Set the batch size according to both training performance and available memory\n",
    "NUM_EPOCHS = 50  # TODO: Set the number of epochs\n",
    "train_val = pd.read_csv(\"train.csv\")\n",
    "test_val = pd.read_csv(\"test_no_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5fef543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading configuration...\n",
      "Loading tokenizer...\n",
      "Loading model...\n",
      "Model loaded to `mps`\n"
     ]
    }
   ],
   "source": [
    "print('Loading configuration...')\n",
    "model_config = GPT2Config.from_pretrained(pretrained_model_name_or_path=\"gpt2\")\n",
    "print('Loading tokenizer...')\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(pretrained_model_name_or_path=\"gpt2\")\n",
    "# default to left padding\n",
    "tokenizer.padding_side = \"left\"\n",
    "# Define PAD Token = EOS Token = 50256\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "# Get the actual model.\n",
    "print('Loading model...')\n",
    "model = GPT2Model.from_pretrained(pretrained_model_name_or_path=\"gpt2\", config=model_config)\n",
    "# resize model embedding to match new tokenizer\n",
    "# model.resize_token_embeddings(len(tokenizer))\n",
    "# fix model padding token id\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "# Load model to defined device.\n",
    "model.to(DEVICE)\n",
    "print('Model loaded to `%s`'%DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "161fdafaedaa5b0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Fill out ReviewDataset\n",
    "# class ReviewDataset(Dataset):\n",
    "#     def __init__(self, data_frame):\n",
    "#         self.text = data_frame[\"title\"].str.cat(data_frame[\"sentence\"], sep = \" \")\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.text)\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         return {\"text\": self.text[index]}\n",
    "\n",
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, data_frame):\n",
    "        self.title = data_frame[\"title\"]\n",
    "        self.sentence = data_frame[\"sentence\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.title)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return {\"title\": self.title[index], \"sentence\": self.sentence[index]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "676f7a012f50e988",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dealing with Train...\n",
      "Created `train_dataset` with 12500 samples\n",
      "Created `train_loader` with 625 batches\n",
      "\n",
      "Dealing with Test...\n",
      "Created `test_dataset` with 1000 samples\n",
      "Created `test_loader` with 50 batches\n"
     ]
    }
   ],
   "source": [
    "print('Dealing with Train...')\n",
    "# Create pytorch dataset.\n",
    "train_dataset = ReviewDataset(train_val)\n",
    "print('Created `train_dataset` with %d samples'%len(train_dataset))\n",
    "\n",
    "# Move pytorch dataset into dataloader.\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=False, num_workers=0, pin_memory=True)\n",
    "print('Created `train_loader` with %d batches'%len(train_loader))\n",
    "\n",
    "print()\n",
    "\n",
    "print('Dealing with Test...')\n",
    "# Create pytorch dataset.\n",
    "test_dataset = ReviewDataset(test_val)\n",
    "print('Created `test_dataset` with %d samples'%len(test_dataset))\n",
    "\n",
    "# Move pytorch dataset into dataloader.\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         shuffle=False, num_workers=0, pin_memory=True)\n",
    "print('Created `test_loader` with %d batches'%len(test_loader))\n",
    "# Additional code if needed\n",
    "embedding_size = 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef734414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings_test = np.zeros((len(test_dataset), 2*embedding_size))\n",
    "# i = 0\n",
    "# with torch.no_grad():\n",
    "#     model.eval()\n",
    "#     for batch in tqdm(test_loader, total=len(test_loader)):\n",
    "#         data = list(batch.values())\n",
    "#         encoded_titles = tokenizer(data[0], return_tensors='pt', padding=True, truncation=False)\n",
    "#         encoded_sentences = tokenizer(data[1], return_tensors='pt', padding=True, truncation=False)\n",
    "#         del data\n",
    "#         encoded_titles.to(DEVICE)\n",
    "#         encoded_sentences.to(DEVICE)\n",
    "#         outputs_titles = model(**encoded_titles)\n",
    "#         outputs_sentences = model(**encoded_sentences)\n",
    "#         word_embeddings_titles = outputs_titles.last_hidden_state * encoded_titles.attention_mask.unsqueeze(-1).float()\n",
    "#         word_embeddings_sentences = outputs_sentences.last_hidden_state * encoded_sentences.attention_mask.unsqueeze(-1).float()\n",
    "#         del outputs_titles\n",
    "#         del outputs_sentences\n",
    "#         sentence_embeddings_titles = word_embeddings_titles.sum(dim=1)\n",
    "#         sentence_embeddings_sentences = word_embeddings_sentences.sum(dim=1)\n",
    "#         del word_embeddings_titles\n",
    "#         del word_embeddings_sentences\n",
    "#         sentence_embeddings_titles /= encoded_titles.attention_mask.sum(dim=1, keepdim=True).float()\n",
    "#         sentence_embeddings_sentences /= encoded_sentences.attention_mask.sum(dim=1, keepdim=True).float()\n",
    "#         del encoded_titles\n",
    "#         del encoded_sentences\n",
    "#         embeddings_test[BATCH_SIZE*i : BATCH_SIZE*(i+1)] = np.hstack([sentence_embeddings_titles.cpu().numpy(), sentence_embeddings_sentences.cpu().numpy()])\n",
    "#         del sentence_embeddings_titles\n",
    "#         del sentence_embeddings_sentences\n",
    "#         i +=1\n",
    "# np.save('embeddings_test.npy', embeddings_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf7954c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings_train = np.zeros((len(train_dataset), 2*embedding_size))\n",
    "# i = 0\n",
    "# with torch.no_grad():\n",
    "#     model.eval()\n",
    "#     for batch in tqdm(train_loader, total=len(train_loader)):\n",
    "#         data = list(batch.values())\n",
    "#         encoded_titles = tokenizer(data[0], return_tensors='pt', padding=True, truncation=False)\n",
    "#         encoded_sentences = tokenizer(data[1], return_tensors='pt', padding=True, truncation=False)\n",
    "#         del data\n",
    "#         encoded_titles.to(DEVICE)\n",
    "#         encoded_sentences.to(DEVICE)\n",
    "#         outputs_titles = model(**encoded_titles)\n",
    "#         outputs_sentences = model(**encoded_sentences)\n",
    "#         word_embeddings_titles = outputs_titles.last_hidden_state * encoded_titles.attention_mask.unsqueeze(-1).float()\n",
    "#         word_embeddings_sentences = outputs_sentences.last_hidden_state * encoded_sentences.attention_mask.unsqueeze(-1).float()\n",
    "#         del outputs_titles\n",
    "#         del outputs_sentences\n",
    "#         sentence_embeddings_titles = word_embeddings_titles.sum(dim=1)\n",
    "#         sentence_embeddings_sentences = word_embeddings_sentences.sum(dim=1)\n",
    "#         del word_embeddings_titles\n",
    "#         del word_embeddings_sentences\n",
    "#         sentence_embeddings_titles /= encoded_titles.attention_mask.sum(dim=1, keepdim=True).float()\n",
    "#         sentence_embeddings_sentences /= encoded_sentences.attention_mask.sum(dim=1, keepdim=True).float()\n",
    "#         del encoded_titles\n",
    "#         del encoded_sentences\n",
    "#         embeddings_train[BATCH_SIZE*i : BATCH_SIZE*(i+1)] = np.hstack([sentence_embeddings_titles.cpu().numpy(), sentence_embeddings_sentences.cpu().numpy()])\n",
    "#         del sentence_embeddings_titles\n",
    "#         del sentence_embeddings_sentences\n",
    "#         i +=1\n",
    "# np.save('embeddings_train.npy', embeddings_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b693ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings_test = np.zeros((len(test_dataset), embedding_size))\n",
    "# i = 0\n",
    "# with torch.no_grad():\n",
    "#     model.eval()\n",
    "#     for batch in tqdm(test_loader, total=len(test_loader)):\n",
    "#         data = list(batch.values())\n",
    "#         encoded = tokenizer(*data, return_tensors='pt', padding=True, truncation=True)\n",
    "#         del data\n",
    "#         encoded.to(DEVICE)\n",
    "#         outputs = model(**encoded)\n",
    "#         word_embeddings = outputs.last_hidden_state * encoded.attention_mask.unsqueeze(-1).float()\n",
    "#         del outputs\n",
    "#         sentence_embeddings = word_embeddings.sum(dim=1)\n",
    "#         del word_embeddings\n",
    "#         sentence_embeddings /= encoded.attention_mask.sum(dim=1, keepdim=True).float()\n",
    "#         del encoded\n",
    "#         embeddings_test[BATCH_SIZE*i : BATCH_SIZE*(i+1)] = sentence_embeddings.cpu().numpy()\n",
    "#         del sentence_embeddings\n",
    "#         i +=1\n",
    "# np.save('embeddings_test.npy', embeddings_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156f8ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings_train = np.zeros((len(train_dataset), embedding_size))\n",
    "# i = 0\n",
    "# with torch.no_grad():\n",
    "#     model.eval()\n",
    "#     for batch in tqdm(train_loader, total=len(train_loader)):\n",
    "#         data = list(batch.values())\n",
    "#         encoded = tokenizer(*data, return_tensors='pt', padding=True, truncation=True)\n",
    "#         del data\n",
    "#         encoded.to(DEVICE)\n",
    "#         outputs = model(**encoded)\n",
    "#         word_embeddings = outputs.last_hidden_state * encoded.attention_mask.unsqueeze(-1).float()\n",
    "#         del outputs\n",
    "#         sentence_embeddings = word_embeddings.sum(dim=1)\n",
    "#         del word_embeddings\n",
    "#         sentence_embeddings /= encoded.attention_mask.sum(dim=1, keepdim=True).float()\n",
    "#         del encoded\n",
    "#         embeddings_train[BATCH_SIZE*i : BATCH_SIZE*(i+1)] = sentence_embeddings.cpu().numpy()\n",
    "#         del sentence_embeddings\n",
    "#         i +=1\n",
    "# np.save('embeddings_train.npy', embeddings_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84c83c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_loader_from_np(X, y=None, train=True, batch_size=BATCH_SIZE, shuffle=True, num_workers=10):\n",
    "    if train:\n",
    "        dataset = TensorDataset(torch.from_numpy(X).type(torch.float), torch.from_numpy(y).type(torch.float))\n",
    "    else:\n",
    "        dataset = TensorDataset(torch.from_numpy(X).type(torch.float))\n",
    "    loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=shuffle, pin_memory=True, num_workers=num_workers)\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf22a570",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_train = np.load('embeddings_train.npy')\n",
    "# embeddings_train = (embeddings_train - np.mean(embeddings_train, axis=1)[:, np.newaxis]) / np.std(embeddings_train, axis=1)[:, np.newaxis]\n",
    "\n",
    "X = embeddings_train\n",
    "y = train_val[\"score\"].to_numpy()\n",
    "train_loader = create_loader_from_np(X[0:round(0.8*X.shape[0])], y[0:round(0.8*len(y))], train=True, batch_size=BATCH_SIZE)\n",
    "valid_loader = create_loader_from_np(X[round(0.2*X.shape[0]):], y[round(0.2*len(y)):], train=True, batch_size=BATCH_SIZE)\n",
    "train_loader_final = create_loader_from_np(X, y, train=True, batch_size=BATCH_SIZE)\n",
    "del X\n",
    "del y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "843f38b9dbea00b0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Fill out MyModule\n",
    "layer1_size = 200\n",
    "layer2_size = 200\n",
    "dropout_prop = 0\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \"\"\"\n",
    "    The model class, which defines our classifier.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        The constructor of the model.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(2*embedding_size, layer1_size)\n",
    "        self.dropout1 = nn.Dropout(dropout_prop)\n",
    "        self.fc2 = nn.Linear(layer1_size, layer2_size)\n",
    "        self.dropout2 = nn.Dropout(dropout_prop)\n",
    "        self.fc3 = nn.Linear(layer2_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        The forward pass of the model.\n",
    "        input: x: torch.Tensor, the input to the model\n",
    "        output: x: torch.Tensor, the output of the model\n",
    "        \"\"\"\n",
    "        x = self.fc1(x)\n",
    "        x = F.elu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.elu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605e5bd0373a1dda",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Net()\n",
    "model.train()\n",
    "model.to(DEVICE)\n",
    "\n",
    "n_epochs = NUM_EPOCHS\n",
    "patience = 10\n",
    "min_delta = 0.001\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "loss_function = nn.MSELoss(reduction=\"sum\")\n",
    "learn_rate = 0.0003\n",
    "optimizer = optim.Adam(model.parameters(), lr=learn_rate)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    train_loss = 0.0\n",
    "    for batch_id, (X, y) in enumerate(train_loader):\n",
    "        model.train()\n",
    "        X = X.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X)\n",
    "        loss = loss_function(torch.flatten(output), y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        if batch_id % 100 == 0:\n",
    "            print('Epoch {}, Batch {}'.format(epoch+1, batch_id), end=\" -- \")\n",
    "    epoch_train_loss = train_loss / len(train_loader.dataset)\n",
    "    print('Epoch {}, training loss {}'.format(epoch+1, epoch_train_loss))\n",
    "\n",
    "    valid_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for X, y in valid_loader: \n",
    "            model.eval()\n",
    "            X = X.to(DEVICE)   \n",
    "            y = y.to(DEVICE)\n",
    "            output_valid = model(X)\n",
    "            loss_valid = loss_function(torch.flatten(output_valid), y)\n",
    "            valid_loss += loss_valid.item()\n",
    "    epoch_valid_loss = valid_loss / len(valid_loader.dataset)\n",
    "    print('Epoch {}, validation loss {}'.format(epoch+1, epoch_valid_loss))\n",
    "\n",
    "    if epoch_valid_loss < best_val_loss - min_delta:\n",
    "        best_val_loss = epoch_valid_loss\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "\n",
    "    if epochs_no_improve >= patience:\n",
    "        print(f'Early stopping after {epoch+1} epochs.')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018536fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "model.train()\n",
    "model.to(DEVICE)\n",
    "n_epochs = 50\n",
    "optimizer = optim.Adam(model.parameters(), lr=learn_rate)\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss = 0.0\n",
    "    for batch_id, (X, y) in enumerate(train_loader_final):\n",
    "        X = X.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X)\n",
    "        loss = loss_function(torch.flatten(output), y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        if batch_id % 100 == 0:\n",
    "            print('Epoch {}, Batch {}'.format(epoch+1, batch_id), end=\" -- \")\n",
    "    epoch_train_loss = train_loss / len(train_loader_final.dataset)\n",
    "    print('Epoch {}, training loss {}'.format(epoch+1, epoch_train_loss))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "657cfdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_test = np.load('embeddings_test.npy')\n",
    "# embeddings_test = (embeddings_test - np.mean(embeddings_test, axis=1)[:, np.newaxis]) / np.std(embeddings_test, axis=1)[:, np.newaxis]\n",
    "\n",
    "X_test = embeddings_test\n",
    "test_loader = create_loader_from_np(X_test, train=False, batch_size=BATCH_SIZE, shuffle=False)\n",
    "del X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60e56bba5fa2d905",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to results.txt\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "results = []\n",
    "with torch.no_grad():\n",
    "    for [x_batch] in test_loader:\n",
    "        x_batch = x_batch.to(DEVICE)\n",
    "        output = torch.flatten(model(x_batch))\n",
    "        output = output.cpu().numpy()[:, np.newaxis]\n",
    "        results.append(output)\n",
    "    results = np.vstack(results)\n",
    "\n",
    "    with open(\"result.txt\", \"w\") as f:\n",
    "        for val in np.concatenate(results):\n",
    "            f.write(f\"{val}\\n\")\n",
    "print(\"Results saved to results.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
