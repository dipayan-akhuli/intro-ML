{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57002395eb6b50f8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Project 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a46aca0e5d9ef",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1c6ff7632991155",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from transformers import AlbertConfig, AlbertTokenizer, AlbertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d9b5e89d4b3a02",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"mps\")\n",
    "BATCH_SIZE = 20\n",
    "NUM_EPOCHS = 50\n",
    "train_val = pd.read_csv(\"train.csv\")\n",
    "test_val = pd.read_csv(\"test_no_score.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c531fad7",
   "metadata": {},
   "source": [
    "#### Loading ALBERT transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5fef543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded to `mps`\n"
     ]
    }
   ],
   "source": [
    "model_config = AlbertConfig.from_pretrained(pretrained_model_name_or_path=\"albert-xxlarge-v2\")\n",
    "tokenizer = AlbertTokenizer.from_pretrained(pretrained_model_name_or_path=\"albert-xxlarge-v2\")\n",
    "tokenizer.padding_side = \"right\"\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = AlbertModel.from_pretrained(pretrained_model_name_or_path=\"albert-xxlarge-v2\", config=model_config)\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "model.to(DEVICE)\n",
    "print('Model loaded to `%s`'%DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d49f942",
   "metadata": {},
   "source": [
    "#### Preparing text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "161fdafaedaa5b0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, data_frame):\n",
    "        self.text = data_frame[\"title\"].str.cat(data_frame[\"sentence\"], sep = \" \")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return {\"text\": self.text[index]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "676f7a012f50e988",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created train_dataset with 12500 samples\n",
      "Created train_loader with 625 batches\n",
      "\n",
      "Created test_dataset with 1000 samples\n",
      "Created test_loader with 50 batches\n"
     ]
    }
   ],
   "source": [
    "train_dataset = ReviewDataset(train_val)\n",
    "print(\"Created train_dataset with %d samples\" %len(train_dataset))\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "print(\"Created train_loader with %d batches\" %len(train_loader))\n",
    "print()\n",
    "test_dataset = ReviewDataset(test_val)\n",
    "print(\"Created test_dataset with %d samples\" %len(test_dataset))\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "print(\"Created test_loader with %d batches\" %len(test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d22df65",
   "metadata": {},
   "source": [
    "#### Extracting text embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50b693ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [06:15<00:00,  7.51s/it]\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 4096\n",
    "embeddings_test = np.zeros((len(test_dataset), embedding_size))\n",
    "i = 0\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for batch in tqdm(test_loader, total=len(test_loader)):\n",
    "        data = list(batch.values())\n",
    "        encoded = tokenizer(*data, return_tensors=\"pt\", padding=True, truncation=False)\n",
    "        del data\n",
    "        encoded.to(DEVICE)\n",
    "        outputs = model(**encoded)\n",
    "        word_embeddings = outputs.last_hidden_state * encoded.attention_mask.unsqueeze(-1).float()\n",
    "        del outputs\n",
    "        sentence_embeddings = word_embeddings.sum(dim=1)\n",
    "        del word_embeddings\n",
    "        sentence_embeddings /= encoded.attention_mask.sum(dim=1, keepdim=True).float()\n",
    "        del encoded\n",
    "        embeddings_test[BATCH_SIZE*i : BATCH_SIZE*(i+1)] = sentence_embeddings.cpu().numpy()\n",
    "        del sentence_embeddings\n",
    "        i += 1\n",
    "np.save(\"embeddings_test.npy\", embeddings_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "156f8ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [1:00:39<00:00,  5.82s/it]\n"
     ]
    }
   ],
   "source": [
    "embeddings_train = np.zeros((len(train_dataset), embedding_size))\n",
    "i = 0\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for batch in tqdm(train_loader, total=len(train_loader)):\n",
    "        data = list(batch.values())\n",
    "        encoded = tokenizer(*data, return_tensors=\"pt\", padding=True, truncation=False)\n",
    "        del data\n",
    "        encoded.to(DEVICE)\n",
    "        outputs = model(**encoded)\n",
    "        word_embeddings = outputs.last_hidden_state * encoded.attention_mask.unsqueeze(-1).float()\n",
    "        del outputs\n",
    "        sentence_embeddings = word_embeddings.sum(dim=1)\n",
    "        del word_embeddings\n",
    "        sentence_embeddings /= encoded.attention_mask.sum(dim=1, keepdim=True).float()\n",
    "        del encoded\n",
    "        embeddings_train[BATCH_SIZE*i : BATCH_SIZE*(i+1)] = sentence_embeddings.cpu().numpy()\n",
    "        del sentence_embeddings\n",
    "        i += 1\n",
    "np.save(\"embeddings_train.npy\", embeddings_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a40e810",
   "metadata": {},
   "source": [
    "#### Preparing training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84c83c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_loader_from_np(X, y=None, train=True, batch_size=BATCH_SIZE, shuffle=True, num_workers=10):\n",
    "    if train:\n",
    "        dataset = TensorDataset(torch.from_numpy(X).type(torch.float), torch.from_numpy(y).type(torch.float))\n",
    "    else:\n",
    "        dataset = TensorDataset(torch.from_numpy(X).type(torch.float))\n",
    "    loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=shuffle, pin_memory=True, num_workers=num_workers)\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf22a570",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_train = np.load(\"embeddings_train.npy\")\n",
    "X = embeddings_train\n",
    "y = train_val[\"score\"].to_numpy()\n",
    "train_loader = create_loader_from_np(X[0:round(0.8*X.shape[0])], y[0:round(0.8*len(y))], train=True, batch_size=BATCH_SIZE)\n",
    "valid_loader = create_loader_from_np(X[round(0.2*X.shape[0]):], y[round(0.2*len(y)):], train=True, batch_size=BATCH_SIZE)\n",
    "train_loader_final = create_loader_from_np(X, y, train=True, batch_size=BATCH_SIZE)\n",
    "del X\n",
    "del y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c99d7a7",
   "metadata": {},
   "source": [
    "#### Defining neural network for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "843f38b9dbea00b0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layer1_size = 500\n",
    "layer2_size = 500\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \"\"\"\n",
    "    The model class, which defines our classifier.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        The constructor of the model.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(embedding_size, layer1_size)\n",
    "        self.fc2 = nn.Linear(layer1_size, layer2_size)\n",
    "        self.fc3 = nn.Linear(layer2_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        The forward pass of the model.\n",
    "        input: x: torch.Tensor, the input to the model\n",
    "        output: x: torch.Tensor, the output of the model\n",
    "        \"\"\"\n",
    "        x = self.fc1(x)\n",
    "        x = F.elu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.elu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392a3ae0",
   "metadata": {},
   "source": [
    "#### Training and evaluating neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605e5bd0373a1dda",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Net()\n",
    "model.train()\n",
    "model.to(DEVICE)\n",
    "\n",
    "n_epochs = NUM_EPOCHS\n",
    "loss_function = nn.MSELoss(reduction=\"sum\")\n",
    "learn_rate = 0.0003\n",
    "optimizer = optim.Adam(model.parameters(), lr=learn_rate)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    train_loss = 0.0\n",
    "    for batch_id, (X, y) in enumerate(train_loader):\n",
    "        model.train()\n",
    "        X = X.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X)\n",
    "        loss = loss_function(torch.flatten(output), y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        if batch_id % 100 == 0:\n",
    "            print(\"Epoch {}, Batch {}\".format(epoch+1, batch_id), end=\" -- \")\n",
    "    epoch_train_loss = train_loss / len(train_loader.dataset)\n",
    "    print(\"Epoch {}, training loss {}\".format(epoch+1, epoch_train_loss))\n",
    "\n",
    "    valid_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for X, y in valid_loader: \n",
    "            model.eval()\n",
    "            X = X.to(DEVICE)   \n",
    "            y = y.to(DEVICE)\n",
    "            output_valid = model(X)\n",
    "            loss_valid = loss_function(torch.flatten(output_valid), y)\n",
    "            valid_loss += loss_valid.item()\n",
    "    epoch_valid_loss = valid_loss / len(valid_loader.dataset)\n",
    "    print(\"Epoch {}, validation loss {}\".format(epoch+1, epoch_valid_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7435f88",
   "metadata": {},
   "source": [
    "#### Training final neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018536fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "model.train()\n",
    "model.to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learn_rate)\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss = 0.0\n",
    "    for batch_id, (X, y) in enumerate(train_loader_final):\n",
    "        X = X.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X)\n",
    "        loss = loss_function(torch.flatten(output), y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        if batch_id % 100 == 0:\n",
    "            print(\"Epoch {}, Batch {}\".format(epoch+1, batch_id), end=\" -- \")\n",
    "    epoch_train_loss = train_loss / len(train_loader_final.dataset)\n",
    "    print(\"Epoch {}, training loss {}\".format(epoch+1, epoch_train_loss))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e93d474",
   "metadata": {},
   "source": [
    "#### Making predictions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "657cfdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_test = np.load(\"embeddings_test.npy\")\n",
    "X_test = embeddings_test\n",
    "test_loader = create_loader_from_np(X_test, train=False, batch_size=BATCH_SIZE, shuffle=False)\n",
    "del X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60e56bba5fa2d905",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to results.txt\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "results = []\n",
    "with torch.no_grad():\n",
    "    for [x_batch] in test_loader:\n",
    "        x_batch = x_batch.to(DEVICE)\n",
    "        output = torch.flatten(model(x_batch))\n",
    "        output = output.cpu().numpy()[:, np.newaxis]\n",
    "        results.append(np.clip(output, a_min=0, a_max=10))\n",
    "    results = np.vstack(results)\n",
    "\n",
    "    with open(\"result.txt\", \"w\") as f:\n",
    "        for val in np.concatenate(results):\n",
    "            f.write(f\"{val}\\n\")\n",
    "print(\"Results saved to results.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
