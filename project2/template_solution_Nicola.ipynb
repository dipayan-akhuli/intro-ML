{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad2e81b29c71eb2b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Task 2\n",
    "This serves as a template which will guide you through the implementation of this task. It is advised to first read the whole template and get a sense of the overall structure of the code before trying to fill in any of the TODO gaps.\n",
    "This is the jupyter notebook version of the template. For the python file version, please refer to the file `template_solution.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de347e31d213bd5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "First, we import necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9e071b8e282a8d6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-10T18:47:37.485752Z",
     "start_time": "2024-03-10T18:47:37.479263Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Add any other imports you need here\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import linear_model, model_selection\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import DotProduct, RBF, Matern, RationalQuadratic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6877146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   price_AUS  price_CHF  price_CZE  price_GER  price_ESP  price_FRA  price_UK  \\\n",
      "0        NaN   9.644028  -1.686248  -1.748076  -3.666005        NaN -1.822720   \n",
      "1        NaN   7.246061  -2.132377  -2.054363  -3.295697  -4.104759 -1.826021   \n",
      "2  -2.101937   7.620085  -1.910282        NaN  -3.388777        NaN -2.034409   \n",
      "3  -2.098475   8.411894  -1.903834        NaN  -3.588235        NaN -2.214720   \n",
      "4  -1.969687   8.926884  -1.697257  -1.331049        NaN  -3.911096 -2.388092   \n",
      "5  -1.935209   8.104719  -1.488434        NaN  -3.878786  -3.831497 -2.275584   \n",
      "\n",
      "   price_ITA  price_POL  price_SVK  season_autumn  season_spring  \\\n",
      "0  -3.931031        NaN  -3.238197            0.0            1.0   \n",
      "1        NaN        NaN  -3.212894            0.0            0.0   \n",
      "2  -4.073850        NaN  -3.114061            1.0            0.0   \n",
      "3  -4.018620  -2.330803        NaN            0.0            0.0   \n",
      "4  -4.093946        NaN        NaN            0.0            1.0   \n",
      "5  -4.014349        NaN        NaN            0.0            0.0   \n",
      "\n",
      "   season_summer  season_winter  \n",
      "0            0.0            0.0  \n",
      "1            1.0            0.0  \n",
      "2            0.0            0.0  \n",
      "3            0.0            1.0  \n",
      "4            0.0            0.0  \n",
      "5            1.0            0.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicolazolliker/anaconda3/envs/iml/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Test: changing season into 4 binary columns\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "\n",
    "# Initialize OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit and transform the data\n",
    "one_hot_encoded = encoder.fit_transform(train_df[['season']])\n",
    "\n",
    "# Convert the one-hot encoded array into a DataFrame\n",
    "one_hot_encoded_df = pd.DataFrame(one_hot_encoded, columns=encoder.get_feature_names_out(['season']))\n",
    "\n",
    "# Concatenate the one-hot encoded DataFrame with the original DataFrame\n",
    "train_df = pd.concat([train_df, one_hot_encoded_df], axis=1)\n",
    "\n",
    "# Drop the original column \n",
    "train_df.drop('season', axis=1, inplace=True)\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(train_df.head(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918f2086e18dd7b5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Data Loading\n",
    "TODO: Perform data preprocessing, imputation and extract X_train, y_train and X_test\n",
    "(and potentially change initialization of variables to accomodate how you deal with non-numeric data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "402e111cb0d70236",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicolazolliker/anaconda3/envs/iml/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/Users/nicolazolliker/anaconda3/envs/iml/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This loads the training and test data, preprocesses it, removes the NaN\n",
    "values and interpolates the missing data using imputation\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "Compute\n",
    "----------\n",
    "X_train: matrix of floats, training input with features\n",
    "y_train: array of floats, training output with labels\n",
    "X_test: matrix of floats: dim = (100, ?), test input with features\n",
    "\"\"\"\n",
    "# Load training data\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "    \n",
    "# Load test data\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "\n",
    "# Dummy initialization of the X_train, X_test and y_train   \n",
    "# TODO: Depending on how you deal with the non-numeric data, you may want to \n",
    "# Initialize OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit and transform the data\n",
    "one_hot_encoded1 = encoder.fit_transform(train_df[['season']])\n",
    "one_hot_encoded2 = encoder.fit_transform(test_df[['season']])\n",
    "\n",
    "# Convert the one-hot encoded array into a DataFrame\n",
    "one_hot_encoded_df1 = pd.DataFrame(one_hot_encoded1, columns=encoder.get_feature_names_out(['season']))\n",
    "one_hot_encoded_df2 = pd.DataFrame(one_hot_encoded2, columns=encoder.get_feature_names_out(['season']))\n",
    "\n",
    "# Concatenate the one-hot encoded DataFrame with the original DataFrame\n",
    "train_df = pd.concat([train_df, one_hot_encoded_df1], axis=1)\n",
    "test_df = pd.concat([test_df, one_hot_encoded_df2], axis=1)\n",
    "\n",
    "# Drop the original column \n",
    "train_df.drop('season', axis=1, inplace=True)\n",
    "test_df.drop('season', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# modify/ignore the initialization of these variables   \n",
    "X_train = np.zeros_like(train_df.drop(['price_CHF'],axis=1))\n",
    "y_train = np.zeros_like(train_df['price_CHF'])\n",
    "X_test = np.zeros_like(test_df)\n",
    "\n",
    "# TODO: Perform data preprocessing, imputation and extract X_train, y_train and X_test\n",
    "#kNN imputation\n",
    "imputer = KNNImputer(n_neighbors=5, weights=\"uniform\")\n",
    "imputed_data = imputer.fit_transform(train_df)\n",
    "train_df = pd.DataFrame(imputed_data, columns=train_df.columns)\n",
    "#transform to numpy\n",
    "X_train = train_df.drop(['price_CHF'],axis=1).values\n",
    "y_train = train_df['price_CHF'].values\n",
    "\n",
    "imputed_data = imputer.fit_transform(test_df)\n",
    "test_df = pd.DataFrame(imputed_data, columns=test_df.columns)\n",
    "#transform to numpy\n",
    "X_test = test_df.values\n",
    "\n",
    "\n",
    "assert (X_train.shape[1] == X_test.shape[1]) and (X_train.shape[0] == y_train.shape[0]) and (X_test.shape[0] == 100), \"Invalid data shape\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9953f086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.12086072 -1.6862481  -1.74807638 ...  1.          0.\n",
      "   0.        ]\n",
      " [-2.12490715 -2.13237679 -2.05436269 ...  0.          1.\n",
      "   0.        ]\n",
      " [-2.10193661 -1.91028232 -1.90464383 ...  0.          0.\n",
      "   0.        ]\n",
      " ...\n",
      " [-0.97115692  0.24527874  0.55847439 ...  0.          1.\n",
      "   0.        ]\n",
      " [-1.16316339  0.29991092  0.78815177 ...  0.          0.\n",
      "   0.        ]\n",
      " [-1.05834258  0.23183488  0.80046006 ...  0.          0.\n",
      "   1.        ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959037466887e870",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Modeling and Prediction\n",
    "TODO: Define the model and fit it using training data. Then, use test data to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9fb0d86b605f9813",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicolazolliker/anaconda3/envs/iml/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:419: ConvergenceWarning: The optimal value found for dimension 0 of parameter sigma_0 is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/nicolazolliker/anaconda3/envs/iml/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:419: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/Users/nicolazolliker/anaconda3/envs/iml/lib/python3.10/site-packages/sklearn/gaussian_process/kernels.py:419: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.87755586  0.97523028  0.93928585  0.97545642]\n",
      " [ 0.90645666  0.93769499 -0.35363157  0.94884853]\n",
      " [ 0.78883046  0.93081321 -0.81307264  0.92003786]\n",
      " [ 0.89476601  0.97350736  0.91091743  0.97491152]\n",
      " [ 0.89718432  0.96781547  0.91414043  0.97259058]]\n",
      "[0.87295866 0.95701226 0.3195279  0.95836898]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This defines the model, fits training data and then does the prediction\n",
    "with the test data \n",
    "\n",
    "Parameters\n",
    "----------\n",
    "X_train: matrix of floats, training input with 10 features\n",
    "y_train: array of floats, training output\n",
    "X_test: matrix of floats: dim = (100, ?), test input with 10 features\n",
    "\n",
    "Compute\n",
    "----------\n",
    "y_test: array of floats: dim = (100,), predictions on test set\n",
    "\"\"\"\n",
    "\n",
    "y_pred=np.zeros(X_test.shape[0])\n",
    "#TODO: Define the model and fit it using training data. Then, use test data to make predictions\n",
    "\n",
    "\n",
    "\n",
    "kernel = [DotProduct(), Matern(), RBF(), RationalQuadratic()]\n",
    "score = np.zeros((5, 4))\n",
    "kf = KFold(n_splits=5)\n",
    "j=0\n",
    "for ker in kernel:\n",
    "    i=0\n",
    "    for train, test in kf.split(X_train):\n",
    "        x_cv, x_valid, y_cv, y_valid = X_train[train], X_train[test], y_train[train], y_train[test]\n",
    "        gpr = GaussianProcessRegressor(kernel=ker, random_state=100)\n",
    "        gpr.fit(x_cv, y_cv)\n",
    "        score[i, j] = gpr.score(x_valid, y_valid)\n",
    "        i+=1\n",
    "    j+=1\n",
    "\n",
    "print(score)\n",
    "print(np.mean(score, axis=0))\n",
    "\n",
    "x = gpr.predict(X_test, return_std=False)\n",
    "y_pred = x\n",
    "\n",
    "\n",
    "assert y_pred.shape == (100,), \"Invalid data shape\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ab81c077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[-1.98141431 -2.34638819 -2.16027943 -0.56083018 -1.85409905 -2.21389683\n",
      " -1.43360329  0.40344926  0.01194177  1.12006564  0.8390515   2.75164235\n",
      "  2.42790331  2.36704077  2.68664547  1.88051352  1.78646943  1.89615272\n",
      "  2.0296672   1.68483961  2.94215121  3.21006158  3.42328871  3.0554868\n",
      "  3.21032899  4.74058067  5.73818542  7.85939994  8.91027594  9.16855723\n",
      "  9.01049924  7.8256356   7.83747002  7.4529233   7.79664999  7.72958615\n",
      "  7.51630042  7.96117223  7.8652117   7.27419389  7.75828939  7.64420712\n",
      "  7.84180254  7.77024952  7.79919723  8.09667712  7.70314666  8.13663762\n",
      "  7.76291149  7.85225175  7.50884851  7.73309586  7.64679099  8.56907397\n",
      "  7.92477373  9.01739373  8.4067652   8.11544504  6.93099617  6.36473016\n",
      "  6.94012544  5.74783812  5.37925     5.47215215  5.20779912  5.25569111\n",
      "  4.67550814  4.76457153  4.16667335  5.32994261  4.41704352  5.31858056\n",
      "  3.82480585  5.65373378  5.73185359  6.30247506  7.52730379  7.52380859\n",
      "  8.07635128  8.29110907  8.34287893  8.36368605  7.58837072  8.18525601\n",
      "  8.74328737  8.63102068  8.74515097  8.01286975  7.82869466  7.3826889\n",
      "  7.44038387  8.07976407  8.84023669  9.17974313  8.12421291  7.76690637\n",
      "  8.43717923  7.93906168  6.73962154  6.39754713]\n"
     ]
    }
   ],
   "source": [
    "gpr = GaussianProcessRegressor(kernel=RationalQuadratic(), random_state=100)\n",
    "gpr.fit(X_train, y_train)\n",
    "y_pred = gpr.predict(X_test)\n",
    "print(gpr.score(X_train, y_train))\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c62e0cd4cec5a7e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Saving Results\n",
    "You don't have to change this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "382d87d2d67ddbdc",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results file successfully generated!\n"
     ]
    }
   ],
   "source": [
    "dt = pd.DataFrame(y_pred) \n",
    "dt.columns = ['price_CHF']\n",
    "dt.to_csv('results_nicola_kNN.csv', index=False)\n",
    "print(\"\\nResults file successfully generated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d46672",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
